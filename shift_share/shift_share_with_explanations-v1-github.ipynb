{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fe34ac",
   "metadata": {},
   "source": [
    "# Instrument Selection Using Shift-Share Weights\n",
    "\n",
    "This Jupyter Notebook provides a numerical example to illustrate how shift-share instruments can help in selecting the correct instruments among potentially endogenous ones.\n",
    "\n",
    "Our goal is to recover $\\theta$ in the following equation where $x$ and $e$ are correlated:\n",
    "\n",
    "$$y = \\theta x + e$$\n",
    "\n",
    "We perform IV regression using two approaches:\n",
    "\n",
    "1. GMM Weighting Using the Standard 2SLS Weighting Matrix\n",
    "2. Using a Custom Weighting Matrix\n",
    "\n",
    "The custom weighting approach is designed to mirror shift weights and provide intuition for how using shifts could reduce endogeneity.\n",
    "\n",
    "## 1. Data Generation Process\n",
    "\n",
    "We generate datasets with a specified correlation structure.\n",
    "\n",
    "### Equations:\n",
    "\n",
    "The model is specified as:\n",
    "\n",
    "$$y = \\theta x + e$$\n",
    "\n",
    "Where $x$ and $e$ are correlated. The parameter `rho_x_e` controls the level of correlation between $x$ and $e$.\n",
    "\n",
    "Instruments $z_1$ and $z_2$ are also correlated with $x$ but have a small correlation with $e$. The level of endogeneity of the instruments is controlled by the parameters `rho_z1_e` and `rho_z2_e`. The higher these parameters, the more endogenous the instruments are, resulting in greater bias.\n",
    "\n",
    "You can think of $z_1$ and $z_2$ as the initial shares in the context of a shift-share analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4617e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.linalg import inv\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def generate_data(n, rho_x_e, rho_z1_e, rho_z2_e, theta):\n",
    "    # Generate noise terms\n",
    "    e = np.random.normal(0, 1, n)\n",
    "    u1 = np.random.normal(0, 1, n)\n",
    "    v1 = np.random.normal(0, 1, n)\n",
    "    v2 = np.random.normal(0, 1, n)\n",
    "\n",
    "    # Generate instruments\n",
    "    z1 = rho_z1_e * e + v1\n",
    "    z2 = rho_z2_e * e + v2\n",
    "\n",
    "    # Generate endogenous regressor\n",
    "    x = z1 + z2 + u1 + rho_x_e * e\n",
    "\n",
    "    # Generate dependent variable\n",
    "    y = theta * x + e\n",
    "\n",
    "    return y, x, e, z1, z2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc923884",
   "metadata": {},
   "source": [
    "\n",
    "## 2. IV Regression with GMM\n",
    "\n",
    "### Standard vs. Custom Weighting Matrix\n",
    "\n",
    "Proposition 1 from [Goldsmith-Pinkham et al. (2020)](https://www.aeaweb.org/articles?id=10.1257/aer.20181047) shows that a shift-share instrument, using $z_1$ and $z_2$ and a vector of shifts $s$, is equivalent to 2SLS just using the initial shares $z_1$ and $z_2$. However, the shifts $s$ change the GMM weighting matrix. As a result, these results only apply when the instruments are exogenous since misspecified GMM estimates depend on the weighting matrix.\n",
    "\n",
    "In our example, where the instruments are endogenous, we expect different results between shift-share and 2SLS. We show that the shift-share instrument can reduce bias by comparing two approaches: \n",
    "- 2SLS with $z_1$ and $z_2$\n",
    "- A custom weighting matrix that ranks the instruments based on their level of endogeneity. \n",
    "\n",
    "\n",
    "### Standard GMM Weighting Matrix\n",
    "\n",
    "The standard GMM weighting matrix for 2SLS is $(Z'Z)^{-1}$.\n",
    "\n",
    "#### Equations: \n",
    "The GMM estimator $\\hat{\\theta}$ is given by:\n",
    "\n",
    "$$\\hat{\\theta} = (X'ZW(Z'X))^{-1}(X'ZW(Z'y))$$\n",
    "\n",
    "### Custom GMM Weighting Matrix\n",
    "The custom weighting matrix is diagonal and inversely proportional to the absolute correlations of $z_1$ and $z_2$ with $e$.\n",
    "\n",
    "#### Equations:\n",
    "The custom GMM estimator $\\hat{\\theta}$ using the custom weighting matrix $W$:\n",
    "\n",
    "$$\\hat{\\theta} = (X'ZW(Z'X))^{-1}(X'ZW(Z'y))$$\n",
    "\n",
    "The custom weighting matrix mirrors the shift-share approach. The variable $s$ doesn't explicitly appear in this code due to time constraints. For simplicity, we directly weight by their known level of endogeneity `rho_z1_e` and `rho_z2_e`. \n",
    "\n",
    "To demonstrate the efficicy of shift-shares in a more general setting, we would need to derive the weighting matrix in terms of the shifts $s$ and provide conditions relating the correlation between $z_1$ and $e$, and the correlation between $z_2$ and $e$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca38c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iv_gmm_standard(y, x, z1, z2):\n",
    "    T = len(y)\n",
    "    Z = np.column_stack([z1, z2])\n",
    "    Z_prime_Z_inv = inv(Z.T @ Z / T)\n",
    "    \n",
    "    W_standard = Z_prime_Z_inv\n",
    "    \n",
    "    X = np.column_stack([x])\n",
    "    theta_hat = inv(X.T @ Z @ W_standard @ Z.T @ X) @ X.T @ Z @ W_standard @ Z.T @ y\n",
    "    \n",
    "    return theta_hat\n",
    "\n",
    "def iv_gmm_custom(y, x, z1, z2, rho_z1_e, rho_z2_e):\n",
    "    T = len(y)\n",
    "    Z = np.column_stack([z1, z2])\n",
    "    \n",
    "    W_custom = np.diag([(1/abs(rho_z1_e)), (1/abs(rho_z2_e))])\n",
    "    \n",
    "    X = np.column_stack([x])\n",
    "    theta_hat = inv(X.T @ Z @ W_custom @ Z.T @ X) @ X.T @ Z @ W_custom @ Z.T @ y\n",
    "    \n",
    "    return theta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e107d0",
   "metadata": {},
   "source": [
    "## 3. Monte Carlo Simulation\n",
    "\n",
    "We run a Monte Carlo simulation to evaluate the performance of each estimator. The provided code implements GMM-based IV estimation under two weighting matrix schemes described above and evaluates their performance.\n",
    "\n",
    "In the simulation, $z_1$ is nearly exogenous (`rho_z1_e= .01`), while $z_2$ is relatively endogenous ( `rho_z2_e =.5`). As a result, the 2SLS approach results in a significant bias for the parameter $\\theta$, ~0.3 over the true value of the parameter ($\\theta = 2$). The bias from the custom weighting matrix is much lower, only ~0.05, which is substantially lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8682ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard GMM Weighting Matrix: Mean estimate and Std Dev 2.292344813872509 0.020306030374386077\n",
      "Custom GMM Weighting Matrix: Mean estimate and Std Dev 2.0543310913499235 0.06752782768508905\n"
     ]
    }
   ],
   "source": [
    "def monte_carlo_sim(n_simulations, n, rho_x_e, rho_z1_e, rho_z2_e, theta):\n",
    "    results_standard = []\n",
    "    results_custom = []\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        y, x, e, z1, z2 = generate_data(n, rho_x_e, rho_z1_e, rho_z2_e, theta)\n",
    "        \n",
    "        theta_standard = iv_gmm_standard(y, x, z1, z2)\n",
    "        theta_custom = iv_gmm_custom(y, x, z1, z2, rho_z1_e, rho_z2_e)\n",
    "        \n",
    "        results_standard.append(theta_standard)\n",
    "        results_custom.append(theta_custom)\n",
    "    \n",
    "    results_standard = np.array(results_standard)\n",
    "    results_custom = np.array(results_custom)\n",
    "    \n",
    "    print(\"Standard GMM Weighting Matrix: Mean estimate and Std Dev\",\n",
    "          results_standard.mean(), results_standard.std())\n",
    "          \n",
    "    print(\"Custom GMM Weighting Matrix: Mean estimate and Std Dev\",\n",
    "          results_custom.mean(), results_custom.std())\n",
    "\n",
    "# Parameters\n",
    "n_simulations = 1000\n",
    "n = 100\n",
    "rho_x_e = 0.5\n",
    "rho_z1_e = 0.01\n",
    "rho_z2_e = 2\n",
    "theta = 2\n",
    "\n",
    "monte_carlo_sim(n_simulations, n, rho_x_e, rho_z1_e, rho_z2_e, theta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
