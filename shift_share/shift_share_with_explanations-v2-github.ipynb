{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fe34ac",
   "metadata": {},
   "source": [
    "# Instrument Selection Using Shift-Share Weights\n",
    "\n",
    "This Jupyter Notebook compares two IV regression approaches:\n",
    "1. Overidentified 2SLS using the initial shares as instruments, without any special weighting scheme.\n",
    "2. Just-identified 2SLS using the shift-share (Bartik) instrument, which uses the initial shares and the growth rates.\n",
    "\n",
    "Our goal is to recover $\\theta$ in the following equation where $x_i$ and $e_i$ are correlated ($i$ is individual):\n",
    "\n",
    "$$y_i = \\theta x_i + e_i$$\n",
    "\n",
    "This notebook shows that the shift-share method can help in selecting the correct instruments and reduce endogeneity bias more effectively than standard 2SLS using the initial shares alone. In this example, the instruments are not completely exogenous. Shift-share lowers endogeneity using the growth rates. The growth rates are proportional to the degree of instrument endogeneity. As a result, we weight better instruments more and worse instruments less when estimating results. \n",
    "\n",
    "## 1. Data Generation Process\n",
    "\n",
    "We generate datasets with a specified correlation structure. The model is specified as:\n",
    "\n",
    "$$y_i = \\theta x_i + e_i$$\n",
    "\n",
    "where $x_i$ and $e_i$ have a small correlated with $e_i$. The parameter $\\rho_{xe}$ controls the level of correlation between $x_i$ and $e_i$.\n",
    "\n",
    "The instruments $z_{ik}^0$ represent shares in a set of three shares, $k = 3$.\n",
    "\n",
    "Instruments $z_{ik}^t$ determine $x_i$ but have a small correlation with $e_i$. The level of endogeneity of the instruments is controlled by the parameters $\\rho_{ze}$. The higher these parameters, the more endogenous the instruments are, resulting in greater bias.\n",
    "\n",
    "$$\n",
    "z_{ik}^0 = 0.3 + N(0, .3) + \\rho_{ze,k} \\cdot e_i\n",
    "$$\n",
    "\n",
    "for $k=1,2$. We ensure the shares are non-negative $z_{i}^0 > 0$ and normalize them if they sum to more than 1.\n",
    "\n",
    "For $k=3$:\n",
    "\n",
    "$$z_{i3}^0 = 1 - z_{i1}^0 - z_{i2}^0$$\n",
    "\n",
    "There are really 3 variables, but just 2 are independent since the third one is a linear combination of the other two.\n",
    "\n",
    "For generating the shares in the next period ($k=1,2$):\n",
    "\n",
    "$$\n",
    "z_{ik}^1 = 0.3 + z_{ik}^0 - \\rho_{ze,k} + N(0, 0.3)\n",
    "$$\n",
    "\n",
    "The growth rates are inversely proportional to the degree of instrument endogeneity $\\rho_{ze}$. As a result, they weight better instruments more and worse instruments less when measuring results. More specifically, proportional to $\\rho_{ze}$.\n",
    "\n",
    "The growth rate of each share $k$ for each of the shares if there are $I$ observations will be $g_k$ where $g_k$ is the sum of $g_{ik}$:\n",
    "\n",
    "$$\n",
    "g_{ik} = \\frac{z_{ik}^1}{z_{ik}^0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "g_k = \\sum_{i} g_{ik}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4617e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "\n",
    "\n",
    "\n",
    "def generate_data(n, rho_z_e, rho_x_e, theta):\n",
    "    k = 3\n",
    "\n",
    "    e = np.random.normal(0, .4, n)\n",
    "    u = np.random.normal(0, .4, n)\n",
    "\n",
    "    # Generate random draws for period 0 with rho_z_e * e tiled\n",
    "    draw_0 = .3 + np.random.normal(0, .3, (n, k-1)) + rho_z_e * np.tile(e[:, np.newaxis], (1, k-1))\n",
    "    \n",
    "    # Ensure Z0 shares are non-negative and sum to 1\n",
    "    Z0 = np.empty((n, k))\n",
    "    Z0[:, 0:2] = draw_0\n",
    "    Z0[:, 2] = 1 - draw_0.sum(axis=1)\n",
    "    Z0 = np.clip(Z0, 0, None)\n",
    "    \n",
    "    # Normalize rows to sum to 1\n",
    "    Z0 = Z0 / Z0.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Generate random draws for period 1\n",
    "    draw_1 = .3 + draw_0 - np.array(rho_z_e) + np.random.normal(0, .3, (n, k-1))\n",
    "\n",
    "    # Ensure Z1 shares are non-negative and sum to 1\n",
    "    Z1 = np.empty((n, k))\n",
    "    Z1[:, 0:2] = draw_1\n",
    "    Z1[:, 2] = 1 - draw_1.sum(axis=1)\n",
    "    Z1 = np.clip(Z1, 0, None)\n",
    "    \n",
    "    # Normalize rows to sum to 1\n",
    "    Z1 = Z1 / Z1.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Calculate growth rates G as the percentage change from Z0 to Z1\n",
    "    G = Z1 / np.maximum(Z0, 1e-5)\n",
    "\n",
    "    # Generate X\n",
    "    x = Z1[:, :k-1] @ np.array([.1, .3]) + rho_x_e * e + u\n",
    "\n",
    "    # Generate Y\n",
    "    y = theta * x + e\n",
    "\n",
    "    return y, x, e, Z0, G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc923884",
   "metadata": {},
   "source": [
    "\n",
    "## 2. IV Regression with GMM\n",
    "\n",
    "### Standard vs. Shift-Share 2SLS\n",
    "\n",
    "This example compares two approaches:\n",
    "- 2SLS with $z_{ik}^0$ as the instrument. This approach uses over-identified 2SLS with $z_{ik}^0$ as an instrument.\n",
    "- Shift-share instrument that uses $z_i^0$ in conjunction with the growth weights by modifying the weights of $z_{ik}^0$ using $g_k$.\n",
    "\n",
    "$$\n",
    "B_i = \\sum_k g_k z_{ik}^0\n",
    "$$\n",
    "\n",
    "Both approaches can be estimated using GMM:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\left(X'ZW(Z'X)\\right)^{-1}\\left(X'ZW(Z'y)\\right)\n",
    "$$\n",
    "\n",
    "They just use different weighting matrices $W$. The shifts $g_k$ determine the GMM weighting matrix with the shift-share instrument.\n",
    "\n",
    "In our example, where the instruments are endogenous, we expect different results between just-identified 2SLS with the shift-share instrument and over-identified 2SLS using the initial shares. We show that the shift-share instrument can reduce bias by comparing two approaches to estimating $\\theta$. Since $g_i$ is inversely proportional to $\\rho_{ze}$, the shift-share instrument weights the instruments by their endogeneity and prioritizes more exogenous variation, thus having less bias compared to 2SLS.\n",
    "\n",
    "### 2SLS Over-Identified Weighting Matrix\n",
    "\n",
    "The GMM estimator $\\hat{\\theta}$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\left(X'ZW(Z'X)\\right)^{-1}\\left(X'ZW(Z'y)\\right)\n",
    "$$\n",
    "\n",
    "The standard GMM weighting matrix for 2SLS is $(Z'Z)^{-1}$. This is computed using `iv_gmm` with the flag `tsls=True`. This just uses the identity matrix as the weights.\n",
    "\n",
    "### Shift-Share GMM Weighting Matrix\n",
    "\n",
    "Proposition 1 from [Goldsmith-Pinkham et al. (2020)](https://www.aeaweb.org/articles?id=10.1257/aer.20181047) shows that two-stage least squares with the shift-share instrument, using the initial shares $z_{ik}^0$ and a vector of average growth rates $g_k$,\n",
    "\n",
    "$$\n",
    "B_i = \\sum_k g_k z_{ik}^0\n",
    "$$\n",
    "\n",
    "is equivalent to the GMM estimator $\\hat{\\theta}$ using the custom weighting matrix $GG'$, where $G$ is a 3x1 vector of the weights $g_k$. In our example, the growth rates are proportional to the degree of instrument endogeneity. As a result, the shift-share approach effectively reduces bias by weighting the instruments appropriately.\n",
    "\n",
    "The shift-share estimator is computed in two ways that are numerically identical: using `iv_gmm` with `tsls=False` (uses shift-share matrix in GMM) or the `bartik_iv` function for just-identified 2SLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca38c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bartik_iv(y, x, Z, G):\n",
    "    avg_G = G.mean(axis=0)  # (1 x K)\n",
    "    Z_bartik = Z @ avg_G   # (N x 1): industry shares weighted by average growth rates\n",
    "    numerator = Z_bartik.T @ y\n",
    "    denominator = Z_bartik.T @ x\n",
    "    \n",
    "    b_bartik = numerator / denominator\n",
    "    return b_bartik\n",
    "\n",
    "def iv_gmm(y, x, Z, G, tsls=False):\n",
    "    avg_G = G.mean(axis=0)  # (1 x K)\n",
    "    avg_G = avg_G.reshape(1, -1)  # Ensure avg_G is row vector (1, K)\n",
    "    W = avg_G.T @ avg_G  # (K x K)\n",
    "\n",
    "    if tsls:\n",
    "        W = np.identity(W.shape[0])\n",
    "    \n",
    "    X = np.column_stack([x])\n",
    "    ZX = Z.T @ X\n",
    "    ZY = Z.T @ y\n",
    "    \n",
    "    theta_hat = inv(ZX.T @ W @ ZX) @ (ZX.T @ W @ ZY)\n",
    "    \n",
    "    return theta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e107d0",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Monte Carlo Simulation\n",
    "\n",
    "We run a Monte Carlo simulation to evaluate the performance of each estimator. The provided code implements GMM-based IV estimation under the two weighting matrix schemes described above and evaluates their performance. \n",
    "- First approach is shift-share IV (using both **Bartik IV Estimate** and **GMM Estimates**). These two approaches are numerically equivalent and provide the exact same results. I compute each respective estimator with GMM and with just-identified 2SLS.\n",
    "- Second approach is 2SLS without a special weighting matrix (**TSLS Estimates**).\n",
    "\n",
    "In the simulation, I set $\\theta=1$. The first share $z_1$ is nearly exogenous while the second share $z_2$ is relatively endogenous (with $\\rho_{ze} = [0.01, 0.4]$). As a result, the bias in the standard 2SLS estimate ($\\hat{\\theta} \\approx 1.45$) is significantly higher compared to the mere -0.1 bias in the Bartik IV and GMM estimates ($\\hat{\\theta} \\approx 0.92$). This highlights how the shift-share instrument can better mitigate endogeneity bias compared to traditional instruments. Adjusting for the growth rates $g_k$ effectively improves the identification of $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8682ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bartik IV Estimates: Mean = 0.920989274325311, Std Dev = 0.16054999842876316\n",
      "GMM Estimates: Mean = 0.920989274325311, Std Dev = 0.16054999842876314\n",
      "TSLS Estimates: Mean = 1.4487093879198176, Std Dev = 0.058198602261687916\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "n = 1000  # number of observations\n",
    "theta = 1.0\n",
    "rho_z_e = [0.01, .4]  # Reduced linkage with error term\n",
    "rho_x_e = 1  # Increased\n",
    "num_simulations = 100  # number of simulations\n",
    "\n",
    "# Containers for results\n",
    "bartik_estimates = []\n",
    "gmm_estimates = []\n",
    "tsls_estimates = []\n",
    "\n",
    "# Run simulations\n",
    "for _ in range(num_simulations):\n",
    "    y, x, e, Z, G = generate_data(n, rho_z_e, rho_x_e, theta)\n",
    "    bartik_estimates.append(bartik_iv(y, x, Z, G))\n",
    "    gmm_estimates.append(iv_gmm(y, x, Z, G)[0])\n",
    "    tsls_estimates.append(iv_gmm(y, x, Z, G, tsls=True)[0])\n",
    "\n",
    "\n",
    "# Convert to numpy arrays for easy computation of mean and standard deviation\n",
    "bartik_estimates = np.array(bartik_estimates)\n",
    "gmm_estimates = np.array(gmm_estimates)\n",
    "tsls_estimates = np.array(tsls_estimates)\n",
    "\n",
    "# Calculate means and standard deviations\n",
    "mean_bartik = bartik_estimates.mean()\n",
    "std_bartik = bartik_estimates.std()\n",
    "mean_gmm = gmm_estimates.mean()\n",
    "std_gmm = gmm_estimates.std()\n",
    "mean_tsls = tsls_estimates.mean()\n",
    "std_tsls = tsls_estimates.std()\n",
    "\n",
    "# Report outcomes and standard deviations\n",
    "print(f\"Bartik IV Estimates: Mean = {mean_bartik}, Std Dev = {std_bartik}\")\n",
    "print(f\"GMM Estimates: Mean = {mean_gmm}, Std Dev = {std_gmm}\")\n",
    "print(f\"TSLS Estimates: Mean = {mean_tsls}, Std Dev = {std_tsls}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
