{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8f9caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def generate_data(n, break_point, alpha0, alpha1, alpha2, beta0, gamma0):\n",
    "    index = np.arange(n).reshape(-1, 1)  # Reshaping for compatibility in column stacking\n",
    "    c2 = np.random.normal(size=n)\n",
    "    e = np.random.normal(size=n)\n",
    "    \n",
    "    # Common random variable to introduce correlation\n",
    "    u1 = np.random.normal(0, 0.5, size=n)  # Shared random factor for correlation\n",
    "    \n",
    "    # Treatment and outcome relationships\n",
    "    d1 = beta0 * (index > break_point).astype(float).reshape(-1) + u1 + np.random.normal(scale=1, size=n)\n",
    "    d2 = gamma0 * (index > (break_point + n * 0.4)).astype(float).reshape(-1) + u1 + np.random.normal(scale=1, size=n)\n",
    "    controls = np.random.normal(scale=2, size=(n, 5)) + u1[:, np.newaxis]  # d3 to d10 with added shared variation\n",
    "    \n",
    "    # Outcome variable should be a 1D array\n",
    "    c1 = alpha0 + alpha1 * c2 + alpha2 * c2 * d1 + e  # Ensure this is 1D\n",
    "\n",
    "    # Ensure data is combined correctly into a 2D array structure, featuring index for reference\n",
    "    #data = np.column_stack((index, c2, d1, d2, controls))\n",
    "    data = np.column_stack((index, c2,  controls))\n",
    "    \n",
    "    return c1, data\n",
    "\n",
    "def compute_delta(c1, data, theta):\n",
    "    index = data[:, 0]\n",
    "    c2 = data[:, 1]\n",
    "    dj = data[:, theta]\n",
    "    \n",
    "    # Regression model with c2 * (index > theta) and interaction with dj\n",
    "    X = sm.add_constant(np.column_stack((c2, c2 * (index >= index[theta]), c2 * dj)))\n",
    "    model = np.linalg.lstsq(X, c1, rcond=None)\n",
    "    coeffs = model[0]\n",
    "    delta = coeffs[2]  # Get the coefficient for the interaction term (c2 * (index >= theta))\n",
    "    \n",
    "    return -1*np.abs(delta), delta\n",
    "\n",
    "\n",
    "n = 250\n",
    "true_break_point = int(n*.5)\n",
    "alpha0 = 0\n",
    "alpha1 = 2\n",
    "alpha2 = 2\n",
    "beta0 = 2\n",
    "gamma0 = 1\n",
    "A_CUTOFF = 500\n",
    "\n",
    "# Generate data with control variables included\n",
    "for i in range(10):\n",
    "    # `generate_data` returns `c1` and the dataset with all covariates including `c2` and `d1` to `d10`\n",
    "    c1, data = generate_data(n, true_break_point, alpha0, alpha1, alpha2, beta0, gamma0)\n",
    "\n",
    "    # Define the range of candidate break points (here, corresponds to control columns in `data`, i.e., `d1`...`d10`)\n",
    "    candidate_breaks = np.arange(2, data.shape[1])  # Starts at 2 to skip index and `c2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875dcbe4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Theta_hat (control variable index chosen): 6\n",
      "Delta coefficient (minimized): (-1.6419096697464919, 1.6419096697464919)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-1.64190967  1.44051614]\n",
      "Mean delta for bootstraps: 1.6419096697464919\n",
      "Variance for delta_hat: 2.0030405928994477\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_covariance(c1, data, theta_tilde, theta_i, n_bootstraps=1000):\n",
    "    results = []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        c1_b, data_b = resample(c1, data)\n",
    "\n",
    "        x_tilde,y_tilde = compute_delta(c1_b, data_b, theta_tilde)\n",
    "        x_i,y_i = compute_delta(c1_b, data_b, theta_i)\n",
    "\n",
    "        results.append((x_i,y_i, x_tilde,y_tilde))\n",
    "\n",
    "    return np.cov(list(zip(*results)))\n",
    "\n",
    "def compute_matrices(cov_matrix, x_tilde,y_tilde,print_stuff=False):\n",
    "    ΣYX_true, ΣY_tilde = cov_matrix[1, 0], cov_matrix[3, 3]\n",
    "    ΣXY_tilde = cov_matrix[2, 3]\n",
    "    ΣYX = cov_matrix[0, 3]# really need the covariance between x and y_tilde\n",
    "    # y and x_tilde would be cov_matrix[1,2]\n",
    "    ΣX, ΣX_tilde = cov_matrix[0, 0], cov_matrix[2, 2]\n",
    "\n",
    "    # Projection calculations using the provided formulation\n",
    "    Z = y_tilde - (ΣYX / ΣY_tilde) * x_tilde\n",
    "    Z_tilde = y_tilde - (ΣXY_tilde / ΣY_tilde) * x_tilde\n",
    "    A = ΣY_tilde**(-2) * (ΣXY_tilde**2 - ΣYX**2)\n",
    "    B = 2 * ΣY_tilde**(-1) * (ΣXY_tilde * Z_tilde - ΣYX * Z)\n",
    "    C = Z_tilde**2 - Z**2\n",
    "\n",
    "    D = B ** 2 - 4 * A * C\n",
    "    H = -C / B if B != 0 else np.nan\n",
    "    G = (-B - np.sqrt(D)) / (2 * A) if D >= 0 and A!=0 else np.nan\n",
    "    K = (-B + np.sqrt(D)) / (2 * A) if D >= 0 and A!=0 else np.nan\n",
    "    if print_stuff:\n",
    "        print('------------------')\n",
    "        print(cov_matrix)\n",
    "        print(ΣYX,'//',cov_matrix[0, 3],  cov_matrix[3, 0],'//',cov_matrix[1,2],cov_matrix[1, 2],'//',ΣYX_true,cov_matrix[0, 1])\n",
    "        \n",
    "    return A, B, C, D, H, G, K\n",
    "\n",
    "\n",
    "def compute_confidence_intervals(theta_tilde, candidate_breaks, c1, data, a_cutoff=1, print_stuff=False):\n",
    "    cached_results = {}\n",
    "    x_tilde, y_tilde = compute_delta(c1, data, theta_tilde)\n",
    "    \n",
    "    # Cache computations to avoid redundant work\n",
    "    for theta in candidate_breaks:\n",
    "        cov_matrix = bootstrap_covariance(c1, data, theta_tilde, theta)\n",
    "        cached_results[theta] = (cov_matrix, x_tilde, y_tilde)\n",
    "    \n",
    "    sigma = cached_results[theta][0][3, 3]\n",
    "    \n",
    "    max_lower_bound = -np.inf\n",
    "    min_upper_bound = np.inf\n",
    "    \n",
    "    for theta in candidate_breaks:\n",
    "        cov_matrix, x_tilde, y_tilde = cached_results[theta]\n",
    "        A, B, C, D, H, G, K = compute_matrices(cov_matrix, x_tilde, y_tilde, print_stuff=print_stuff)\n",
    "        \n",
    "        # Compute bounds under the specified constraints A > 0 and D >= 0\n",
    "        if A > 0 and D >= 0:\n",
    "            max_lower_bound = max(max_lower_bound, G)\n",
    "            min_upper_bound = min(min_upper_bound, K)\n",
    "    \n",
    "    return np.array([max_lower_bound, min_upper_bound]), y_tilde, sigma\n",
    "\n",
    "\n",
    "\n",
    "# Generate data with control variables included\n",
    "for i in range(1):\n",
    "    # `generate_data` returns `c1` and the dataset with all covariates including `c2` and `d1` to `d10`\n",
    "    c1, data = generate_data(n, true_break_point, alpha0, alpha1, alpha2, beta0, gamma0)\n",
    "\n",
    "    # Define the range of candidate break points (here, corresponds to control columns in `data`, i.e., `d1`...`d10`)\n",
    "    candidate_breaks = np.arange(2, data.shape[1])  # Starts at 2 to skip index and `c2`\n",
    "    \n",
    "    # Find the theta (control variable) that gives the minimum delta coefficient\n",
    "    theta_hat, min_delta = max(\n",
    "        ((theta, compute_delta(c1, data, theta)) for theta in candidate_breaks),\n",
    "        key=lambda x: x[1]\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    # Calculate confidence intervals based on `theta_hat`\n",
    "    interval_left, mean, variance = compute_confidence_intervals(\n",
    "        theta_hat, candidate_breaks, c1, data, a_cutoff=A_CUTOFF\n",
    "    )\n",
    "\n",
    "    # Output results\n",
    "    print(f\"Iteration {i+1}:\")\n",
    "    print(\"Theta_hat (control variable index chosen):\", theta_hat)\n",
    "    print(\"Delta coefficient (minimized):\", min_delta)\n",
    "    print(\"Confidence Intervals:\")\n",
    "    print(\"Left Interval:\", interval_left)\n",
    "    print(\"Mean delta for bootstraps:\", mean)\n",
    "    print(\"Variance for delta_hat:\", variance)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178342d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8676618854186884 0.8676618854186879\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def truncated_normal_quantile(quantile, interval, mean, variance):\n",
    "    # Unpack the continuous interval\n",
    "    u1, l2 = interval\n",
    "    \n",
    "    # Standardize the interval with the mean and variance\n",
    "    u1_std, l2_std = (u1 - mean) / np.sqrt(variance), (l2 - mean) / np.sqrt(variance)\n",
    "    \n",
    "    # Calculate the total probability over the single continuous interval\n",
    "    P_total = norm.cdf(l2_std) - norm.cdf(u1_std)\n",
    "    \n",
    "    # Target cumulative probability adjusted for truncation\n",
    "    adjusted_quantile = quantile * P_total\n",
    "    \n",
    "    # Compute the quantile value in the standardized normal space\n",
    "    quantile_value_std = norm.ppf(norm.cdf(u1_std) + adjusted_quantile)\n",
    "    \n",
    "    # Convert back to the original scale\n",
    "    quantile_value = quantile_value_std * np.sqrt(variance) + mean\n",
    "    \n",
    "    return quantile_value\n",
    "\n",
    "# Example usage\n",
    "mean = 0\n",
    "variance = 1\n",
    "interval = (-1.0, 1.0)  # Example continuous interval [u1, l2]\n",
    "\n",
    "quantile_upper = truncated_normal_quantile(0.95, interval, mean, variance)\n",
    "quantile_lower = truncated_normal_quantile(0.05, interval, mean, variance)\n",
    "print(quantile_lower, quantile_upper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
