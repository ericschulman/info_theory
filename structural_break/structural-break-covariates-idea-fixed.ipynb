{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8f9caa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1.2983524700610847, 1.2983524700610847)\n",
      "(-1.33090178394337, 1.33090178394337)\n",
      "(-1.2877784813586688, 1.2877784813586688)\n",
      "(-1.3223570586370166, 1.3223570586370166)\n",
      "(-1.324457530538616, 1.324457530538616)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# Function to generate synthetic data\n",
    "def generate_data(n, break_point, alpha0, alpha1, alpha2, beta0, gamma0):\n",
    "    index = np.arange(n).reshape(-1, 1)\n",
    "    c2 = np.random.normal(size=n)\n",
    "    e = np.random.normal(size=n)\n",
    "    u1 = np.random.normal(0, 0.5, size=n)  # Shared random factor for correlation\n",
    "    \n",
    "    d1 = beta0 * (index > break_point).astype(float).reshape(-1) - u1 + np.random.normal(scale=1, size=n)\n",
    "    d2 = gamma0 * (index > (break_point + n * 0.4)).astype(float).reshape(-1) - u1 + np.random.normal(scale=1, size=n)\n",
    "    controls = np.random.normal(scale=2, size=(n, 5)) - u1[:, np.newaxis]  # d3 to d10 with added shared variation\n",
    "    \n",
    "    c1 = alpha0 + alpha1 * c2 + alpha2 * d1 + e\n",
    "    \n",
    "    data = np.column_stack((index, c2, controls)) #,d1, d2, \n",
    "    return c1, data\n",
    "\n",
    "# Function to compute delta and return model parameters\n",
    "def compute_delta(c1, data, theta, break_point):\n",
    "    index = data[:, 0]\n",
    "    c2 = data[:, 1]\n",
    "    dj = data[:, theta]\n",
    "    \n",
    "    X = sm.add_constant(np.column_stack((c2, c2 * (index >= break_point), dj)))\n",
    "    model = np.linalg.lstsq(X, c1, rcond=None)\n",
    "    coeffs = model[0]\n",
    "    delta = coeffs[2]\n",
    "    return -1*np.abs(delta), delta\n",
    "\n",
    "\n",
    "n = 250\n",
    "true_break_point = int(n*.5)\n",
    "alpha0 = 0\n",
    "alpha1 = 2\n",
    "alpha2 = 3\n",
    "beta0 = 2\n",
    "gamma0 = 1\n",
    "A_CUTOFF = 500\n",
    "\n",
    "# `generate_data` returns `c1` and the dataset with all covariates including `c2` and `d1` to `d10`\n",
    "c1, data = generate_data(n, true_break_point, alpha0, alpha1, alpha2, beta0, gamma0)\n",
    "\n",
    "# Define the range of candidate break points (here, corresponds to control columns in `data`, i.e., `d1`...`d10`)\n",
    "candidate_breaks = np.arange(2, data.shape[1])  # Starts at 2 to skip index and `c2`\n",
    "for theta in candidate_breaks:\n",
    "    print(compute_delta(c1, data, theta, true_break_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875dcbe4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Theta_hat (control variable index chosen): 4\n",
      "Delta coefficient (minimized): (-0.3014280360443669, 0.3014280360443669)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-0.30142804  0.26758001]\n",
      "Mean delta for bootstraps: 0.3014280360443669\n",
      "Variance for delta_hat: 0.3673765146046641\n",
      "-----\n",
      "Iteration 2:\n",
      "Theta_hat (control variable index chosen): 2\n",
      "Delta coefficient (minimized): (-0.07109730589616477, -0.07109730589616477)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-0.07109731  0.19245716]\n",
      "Mean delta for bootstraps: -0.07109730589616477\n",
      "Variance for delta_hat: 0.2760668668776926\n",
      "-----\n",
      "Iteration 3:\n",
      "Theta_hat (control variable index chosen): 3\n",
      "Delta coefficient (minimized): (-0.09968152670790888, -0.09968152670790888)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-0.09968153  0.29556245]\n",
      "Mean delta for bootstraps: -0.09968152670790888\n",
      "Variance for delta_hat: 0.36014338069785895\n",
      "-----\n",
      "Iteration 4:\n",
      "Theta_hat (control variable index chosen): 6\n",
      "Delta coefficient (minimized): (-0.06571673150647744, 0.06571673150647744)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-0.06571673  0.13025461]\n",
      "Mean delta for bootstraps: 0.06571673150647744\n",
      "Variance for delta_hat: 0.3415744145473582\n",
      "-----\n",
      "Iteration 5:\n",
      "Theta_hat (control variable index chosen): 4\n",
      "Delta coefficient (minimized): (-0.49325977922005687, 0.49325977922005687)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-0.49325978  0.13417719]\n",
      "Mean delta for bootstraps: 0.49325977922005687\n",
      "Variance for delta_hat: 0.24948589404659294\n",
      "-----\n",
      "Iteration 6:\n",
      "Theta_hat (control variable index chosen): 5\n",
      "Delta coefficient (minimized): (-0.2647115915292372, 0.2647115915292372)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-0.26471159  0.28999201]\n",
      "Mean delta for bootstraps: 0.2647115915292372\n",
      "Variance for delta_hat: 0.37340948969746174\n",
      "-----\n",
      "Iteration 7:\n",
      "Theta_hat (control variable index chosen): 5\n",
      "Delta coefficient (minimized): (-0.043980193490183575, -0.043980193490183575)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-0.04398019 -0.04398019]\n",
      "Mean delta for bootstraps: -0.043980193490183575\n",
      "Variance for delta_hat: 0.5371383193643797\n",
      "-----\n",
      "Iteration 8:\n",
      "Theta_hat (control variable index chosen): 5\n",
      "Delta coefficient (minimized): (-0.7276772252699748, 0.7276772252699748)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-0.72767723  0.16516492]\n",
      "Mean delta for bootstraps: 0.7276772252699748\n",
      "Variance for delta_hat: 0.32134643468744195\n",
      "-----\n",
      "Iteration 9:\n",
      "Theta_hat (control variable index chosen): 2\n",
      "Delta coefficient (minimized): (-0.4986145118582908, 0.4986145118582908)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-0.49861451  0.20873007]\n",
      "Mean delta for bootstraps: 0.4986145118582908\n",
      "Variance for delta_hat: 0.3337267067139766\n",
      "-----\n",
      "Iteration 10:\n",
      "Theta_hat (control variable index chosen): 2\n",
      "Delta coefficient (minimized): (-1.085423705561705, 1.085423705561705)\n",
      "Confidence Intervals:\n",
      "Left Interval: [-1.08542371  0.05519524]\n",
      "Mean delta for bootstraps: 1.085423705561705\n",
      "Variance for delta_hat: 0.34501820382175125\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_covariance(c1, data, theta_tilde, theta_i,break_point, n_bootstraps=1000):\n",
    "    results = []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        c1_b, data_b = resample(c1, data)\n",
    "\n",
    "        x_tilde,y_tilde = compute_delta(c1_b, data_b, theta_tilde,break_point)\n",
    "        x_i,y_i = compute_delta(c1_b, data_b, theta_i,break_point)\n",
    "\n",
    "        results.append((x_i,y_i, x_tilde,y_tilde))\n",
    "\n",
    "    return np.cov(list(zip(*results)))\n",
    "\n",
    "def compute_matrices(cov_matrix, x_tilde,y_tilde,print_stuff=False):\n",
    "    ΣYX_true, ΣY_tilde = cov_matrix[1, 0], cov_matrix[3, 3]\n",
    "    ΣXY_tilde = cov_matrix[2, 3]\n",
    "    ΣYX = cov_matrix[0, 3]# really need the covariance between x and y_tilde\n",
    "    # y and x_tilde would be cov_matrix[1,2]\n",
    "    ΣX, ΣX_tilde = cov_matrix[0, 0], cov_matrix[2, 2]\n",
    "\n",
    "    # Projection calculations using the provided formulation\n",
    "    Z = y_tilde - (ΣYX / ΣY_tilde) * x_tilde\n",
    "    Z_tilde = y_tilde - (ΣXY_tilde / ΣY_tilde) * x_tilde\n",
    "    A = ΣY_tilde**(-2) * (ΣXY_tilde**2 - ΣYX**2)\n",
    "    B = 2 * ΣY_tilde**(-1) * (ΣXY_tilde * Z_tilde - ΣYX * Z)\n",
    "    C = Z_tilde**2 - Z**2\n",
    "\n",
    "    D = B ** 2 - 4 * A * C\n",
    "    H = -C / B if B != 0 else np.nan\n",
    "    G = (-B - np.sqrt(D)) / (2 * A) if D >= 0 and A!=0 else np.nan\n",
    "    K = (-B + np.sqrt(D)) / (2 * A) if D >= 0 and A!=0 else np.nan\n",
    "    if False:\n",
    "        print('------------------')\n",
    "        print(cov_matrix)\n",
    "        print(ΣYX,'//',cov_matrix[0, 3],  cov_matrix[3, 0],'//',cov_matrix[1,2],cov_matrix[1, 2],'//',ΣYX_true,cov_matrix[0, 1])\n",
    "        \n",
    "    return A, B, C, D, H, G, K\n",
    "\n",
    "\n",
    "def compute_confidence_intervals(theta_tilde, candidate_breaks, c1, data, a_cutoff=1, break_point =true_break_point,\n",
    "                                 print_stuff=False):\n",
    "    cached_results = {}\n",
    "    x_tilde, y_tilde = compute_delta(c1, data, theta_tilde,break_point)\n",
    "    \n",
    "    # Cache computations to avoid redundant work\n",
    "    for theta in candidate_breaks:\n",
    "        cov_matrix = bootstrap_covariance(c1, data, theta_tilde, theta,break_point)\n",
    "        cached_results[theta] = (cov_matrix, x_tilde, y_tilde)\n",
    "    \n",
    "    sigma = cached_results[theta][0][3, 3]\n",
    "    \n",
    "    max_lower_bound = -np.inf\n",
    "    min_upper_bound = np.inf\n",
    "    \n",
    "    for theta in candidate_breaks:\n",
    "        cov_matrix, x_tilde, y_tilde = cached_results[theta]\n",
    "        A, B, C, D, H, G, K = compute_matrices(cov_matrix, x_tilde, y_tilde, print_stuff=print_stuff)\n",
    "        if print_stuff:\n",
    "            print(A, B, C,'//', D, H,'//', G, K)\n",
    "        # Compute bounds under the specified constraints A > 0 and D >= 0\n",
    "        if A > 0 and D >= 0:\n",
    "            max_lower_bound = max(max_lower_bound, G)\n",
    "            min_upper_bound = min(min_upper_bound, K)\n",
    "        if A < 0 and D >= 0:\n",
    "            max_lower_bound = max(max_lower_bound, K) #swap K and G if A is negative...\n",
    "            min_upper_bound = min(min_upper_bound, G)\n",
    "            \n",
    "    return np.array([max_lower_bound, min_upper_bound]), y_tilde, sigma\n",
    "    #TODO add in these constraints A =0... or clsoe to it...\n",
    "    #Y ( ˜θ)≥ −CZ( ˜θ,θ) BZ( ˜θ,θ) ∀θ∈Θ s.t. A( ˜θ,θ)=0 \n",
    "    #and BZ( ˜θ,θ)>0, Y ( ˜θ)≤ −CZ( ˜θ,θ) BZ( ˜θ,θ) ∀θ∈Θ s.t. A( ˜θ,θ)=0 and BZ( ˜θ,θ)<0\n",
    "\n",
    "\n",
    "# Generate data with control variables included\n",
    "for i in range(10):\n",
    "    # `generate_data` returns `c1` and the dataset with all covariates including `c2` and `d1` to `d10`\n",
    "    c1, data = generate_data(n, true_break_point, alpha0, alpha1, alpha2, beta0, gamma0)\n",
    "\n",
    "    # Define the range of candidate break points (here, corresponds to control columns in `data`, i.e., `d1`...`d10`)\n",
    "    candidate_breaks = np.arange(2, data.shape[1])  # Starts at 2 to skip index and `c2`\n",
    "    \n",
    "    # Find the theta (control variable) that gives the minimum delta coefficient\n",
    "    theta_hat, min_delta = max(\n",
    "        ((theta, compute_delta(c1, data, theta,true_break_point)) for theta in candidate_breaks),\n",
    "        key=lambda x: x[1]\n",
    "    )\n",
    "    \n",
    "    # Calculate confidence intervals based on `theta_hat`\n",
    "    interval_left, mean, variance = compute_confidence_intervals(\n",
    "        theta_hat, candidate_breaks, c1, data, a_cutoff=A_CUTOFF\n",
    "    )\n",
    "\n",
    "    # Output results\n",
    "    print(f\"Iteration {i+1}:\")\n",
    "    print(\"Theta_hat (control variable index chosen):\", theta_hat)\n",
    "    print(\"Delta coefficient (minimized):\", min_delta)\n",
    "    print(\"Confidence Intervals:\")\n",
    "    print(\"Left Interval:\", interval_left)\n",
    "    print(\"Mean delta for bootstraps:\", mean)\n",
    "    print(\"Variance for delta_hat:\", variance)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "178342d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5969700469539285 0.04133393961952425\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def truncated_normal_quantile(quantile, interval, mean, variance):\n",
    "    # Unpack the continuous interval\n",
    "    u1, l2 = interval\n",
    "    \n",
    "    # Standardize the interval with the mean and variance\n",
    "    u1_std, l2_std = (u1 - mean) / np.sqrt(variance), (l2 - mean) / np.sqrt(variance)\n",
    "    \n",
    "    # Calculate the total probability over the single continuous interval\n",
    "    P_total = norm.cdf(l2_std) - norm.cdf(u1_std)\n",
    "    \n",
    "    # Target cumulative probability adjusted for truncation\n",
    "    adjusted_quantile = quantile * P_total\n",
    "    \n",
    "    # Compute the quantile value in the standardized normal space\n",
    "    quantile_value_std = norm.ppf(norm.cdf(u1_std) + adjusted_quantile)\n",
    "    \n",
    "    # Convert back to the original scale\n",
    "    quantile_value = quantile_value_std * np.sqrt(variance) + mean\n",
    "    \n",
    "    return quantile_value\n",
    "\n",
    "\n",
    "quantile_upper = truncated_normal_quantile(0.95, interval_left, mean, variance)\n",
    "quantile_lower = truncated_normal_quantile(0.05, interval_left, mean, variance)\n",
    "print(quantile_lower, quantile_upper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
