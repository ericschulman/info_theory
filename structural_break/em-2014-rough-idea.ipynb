{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b6ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from scipy.stats import norm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aeb7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS_loglike(GenericLikelihoodModel):\n",
    "    \n",
    "    def __init__(self, *args, ols=False, **kwargs):\n",
    "        super(OLS_loglike, self).__init__(*args, **kwargs)\n",
    "        self.ols = ols\n",
    "\n",
    "    def loglikeobs(self, params):\n",
    "        y = self.endog\n",
    "        x = self.exog\n",
    "        mu_y = np.dot(x, params)\n",
    "        resid = y - mu_y\n",
    "        sigma = np.sqrt(np.sum(resid**2) / resid.shape[0])\n",
    "        pr_y = norm.logpdf(resid, loc=0, scale=sigma)\n",
    "        return pr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b357a2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Original_Index': 2, 'Delta': -0.05973123790690391, 'Log_Likelihood': -135.6676001512741, 'Rank': 1}\n",
      "{'Original_Index': 3, 'Delta': -0.07212115200793941, 'Log_Likelihood': -138.90323215665148, 'Rank': 2}\n",
      "{'Original_Index': 4, 'Delta': -0.13606142849898198, 'Log_Likelihood': -141.65357815305615, 'Rank': 3}\n",
      "{'Original_Index': 5, 'Delta': -0.1407495056215835, 'Log_Likelihood': -141.6708619166173, 'Rank': 4}\n",
      "{'Original_Index': 6, 'Delta': -0.1424646189581829, 'Log_Likelihood': -140.91607462003904, 'Rank': 5}\n",
      "{'Original_Index': 7, 'Delta': -0.14767115320700236, 'Log_Likelihood': -141.8251104197545, 'Rank': 6}\n",
      "{'Original_Index': 8, 'Delta': -0.16233449561815072, 'Log_Likelihood': -141.55098813813356, 'Rank': 7}\n"
     ]
    }
   ],
   "source": [
    "# Function to generate synthetic data\n",
    "def generate_data(n, break_point, alpha0, alpha1, alpha2, beta0, gamma0):\n",
    "    index = np.arange(n).reshape(-1, 1)\n",
    "    c2 = np.random.normal(size=n)\n",
    "    e = np.random.normal(size=n)\n",
    "    u1 = np.random.normal(0, 0.5, size=n)  # Shared random factor for correlation\n",
    "    \n",
    "    d1 = beta0 * (index > break_point).astype(float).reshape(-1) + u1 + np.random.normal(scale=1, size=n)\n",
    "    d2 = gamma0 * (index > (break_point + n * 0.4)).astype(float).reshape(-1) + u1 + np.random.normal(scale=1, size=n)\n",
    "    controls = np.random.normal(scale=2, size=(n, 5)) + u1[:, np.newaxis]  # d3 to d10 with added shared variation\n",
    "    \n",
    "    c1 = alpha0 + alpha1 * c2 + alpha2 * d1 + e\n",
    "    \n",
    "    data = np.column_stack((index, c2, d1, d2, controls))\n",
    "    return c1, data\n",
    "\n",
    "# Function to compute delta and return model parameters\n",
    "def compute_delta(c1, data, theta, break_point):\n",
    "    index = data[:, 0]\n",
    "    c2 = data[:, 1]\n",
    "    dj = data[:, theta]\n",
    "    \n",
    "    X = sm.add_constant(np.column_stack((c2, c2 * (index >= break_point), dj)))\n",
    "    model = np.linalg.lstsq(X, c1, rcond=None)\n",
    "    coeffs = model[0]\n",
    "    delta = coeffs[2]\n",
    "    \n",
    "    return delta, coeffs\n",
    "\n",
    "# Function to calculate log-likelihood for model parameters\n",
    "def calculate_log_likelihood(c1, X, params):\n",
    "    model = OLS_loglike(c1, X)\n",
    "    log_like_val = model.loglikeobs(params).sum()\n",
    "    return log_like_val\n",
    "\n",
    "# Function to rank deltas and create result dictionary\n",
    "def rank_deltas(c1, data, theta_values, break_point):\n",
    "    results = []\n",
    "    for theta in theta_values:\n",
    "        delta, params = compute_delta(c1, data, theta, break_point)\n",
    "        \n",
    "        index = data[:, 0]\n",
    "        c2 = data[:, 1]\n",
    "        dj = data[:, theta]\n",
    "        X = sm.add_constant(np.column_stack((c2, c2 * (index >= break_point), dj)))\n",
    "        \n",
    "        log_likelihood = calculate_log_likelihood(c1, X, params)\n",
    "        \n",
    "        result = {\n",
    "            'Original_Index': theta,\n",
    "            'Delta': delta,\n",
    "            'Log_Likelihood': log_likelihood\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    # Sort results based on absolute delta\n",
    "    results_sorted = sorted(results, key=lambda x: np.abs(x['Delta']))\n",
    "    \n",
    "    # Add ranking to each result\n",
    "    for rank, entry in enumerate(results_sorted, start=1):\n",
    "        entry['Rank'] = rank\n",
    "    \n",
    "    return results_sorted\n",
    "\n",
    "# Generate a sample data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "break_point = 50\n",
    "alpha0, alpha1, alpha2 = 1.0, 0.5, 0.3\n",
    "beta0, gamma0 = 1.0, -1.0\n",
    "\n",
    "c1, data = generate_data(n, break_point, alpha0, alpha1, alpha2, beta0, gamma0)\n",
    "\n",
    "# Calculate rankings based on deltas\n",
    "theta_values = range(2, data.shape[1])\n",
    "results = rank_deltas(c1, data, theta_values, break_point)\n",
    "\n",
    "# Print the sorted results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702f5a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-120.9598053  -111.97681321 -141.45069697 ... -100.54227656\n",
      "   -92.83441123 -129.09379577]\n",
      " [-123.66112699 -111.28942829 -106.55331004 ... -141.89234256\n",
      "  -109.35662158 -118.79078779]\n",
      " [-195.86511141 -193.90528485 -202.95892123 ... -192.17705114\n",
      "  -200.44041782 -221.93241486]\n",
      " ...\n",
      " [-211.41032165 -168.5467214  -178.79042123 ... -178.87676637\n",
      "  -203.63572674 -225.12275169]\n",
      " [-200.05933281 -186.76117052 -205.92310882 ... -196.88398081\n",
      "  -221.74235396 -207.2389878 ]\n",
      " [-242.91579412 -207.08834607 -233.96480496 ... -205.42694609\n",
      "  -208.61733685 -263.28000998]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Function to generate synthetic data\n",
    "def generate_data(n, break_point, alpha0, alpha1, alpha2, beta0, gamma0):\n",
    "    index = np.arange(n).reshape(-1, 1)\n",
    "    c2 = np.random.normal(size=n)\n",
    "    e = np.random.normal(size=n)\n",
    "    u1 = np.random.normal(0, 0.5, size=n)\n",
    "\n",
    "    d1 = beta0 * (index > break_point).astype(float).reshape(-1) + u1 + np.random.normal(scale=1, size=n)\n",
    "    d2 = gamma0 * (index > (break_point + n * 0.4)).astype(float).reshape(-1) + u1 + np.random.normal(scale=1, size=n)\n",
    "    controls = np.random.normal(scale=2, size=(n, 5)) + u1[:, np.newaxis]\n",
    "\n",
    "    c1 = alpha0 + alpha1 * c2 + alpha2 * d1 + e\n",
    "\n",
    "    data = np.column_stack((index, c2, d1, d2, controls))\n",
    "    return c1, data\n",
    "\n",
    "# Custom OLS Log-Likelihood model\n",
    "class OLS_loglike(GenericLikelihoodModel):\n",
    "    def __init__(self, *args, ols=False, **kwargs):\n",
    "        super(OLS_loglike, self).__init__(*args, **kwargs)\n",
    "        self.ols = ols\n",
    "\n",
    "    def loglikeobs(self, params):\n",
    "        y = self.endog\n",
    "        x = self.exog\n",
    "        mu_y = np.dot(x, params)\n",
    "        resid = y - mu_y\n",
    "        sigma = np.sqrt(np.sum(resid**2) / resid.shape[0])\n",
    "        pr_y = norm.logpdf(resid, loc=0, scale=sigma)\n",
    "        return pr_y\n",
    "\n",
    "# Simulation setup\n",
    "n = 250\n",
    "true_break_point = int(n * 0.5)\n",
    "alpha0, alpha1 = 1.0, 0.5\n",
    "alpha2, beta0, gamma0 = 0.3, 1.0, -1.0\n",
    "mu_delta, sigma_delta = 2.0, 1.0\n",
    "bootstrap_iterations = 100\n",
    "num_draws = 100\n",
    "\n",
    "# Generate base data\n",
    "np.random.seed(42)\n",
    "c1, data = generate_data(n, true_break_point, alpha0, alpha1, alpha2, beta0, gamma0)\n",
    "indices = np.arange(data.shape[1])[2:]\n",
    "\n",
    "# Function to simulate the deltas and calculate the likelihood ratio for configurations\n",
    "def calculate_likelihood_distribution(c1, data, indices, true_break_point, num_draws, bootstrap_iterations):\n",
    "    likelihood_ratios = np.zeros((len(indices), num_draws * bootstrap_iterations))\n",
    "    \n",
    "    for i, theta in enumerate(indices):\n",
    "        for draw in range(num_draws):\n",
    "            np.random.seed(draw)\n",
    "            \n",
    "            # Simulate deltas\n",
    "            deltas = np.hstack([\n",
    "                np.random.normal(mu_delta, sigma_delta, size=bootstrap_iterations),\n",
    "                np.random.normal(-mu_delta, sigma_delta, size=bootstrap_iterations)\n",
    "            ])\n",
    "            \n",
    "            # Bootstrap data and parameters\n",
    "            for j in range(bootstrap_iterations):\n",
    "                delta = deltas[j]\n",
    "                \n",
    "                # Bootstrap sample\n",
    "                data_bootstrap = data[np.random.choice(n, n, replace=True)]\n",
    "                \n",
    "                # Use a model with fixed parameters except for delta\n",
    "                index = data_bootstrap[:, 0]\n",
    "                c2 = data_bootstrap[:, 1]\n",
    "                cj = data_bootstrap[:, theta]\n",
    "                \n",
    "                X_fixed = sm.add_constant(np.column_stack((c2, cj)))\n",
    "                params_fixed = np.linalg.lstsq(X_fixed, c1, rcond=None)[0]\n",
    "                \n",
    "                # Calculate c1 using bootstrap draws and compute likelihood\n",
    "                c1_bootstrap = params_fixed[0] + params_fixed[1]*c2 + alpha2*cj + delta*c2*(index > true_break_point) + np.random.normal(size=n)\n",
    "                X_full = sm.add_constant(np.column_stack((c2, (index > true_break_point), cj)))\n",
    "                \n",
    "                likelihood_no_delta = calculate_log_likelihood(c1_bootstrap, X_fixed, params_fixed)\n",
    "                \n",
    "                # Apply the model with the current estimated parameters (including delta)\n",
    "                params_full = np.hstack([params_fixed, delta])\n",
    "                likelihood_with_delta = calculate_log_likelihood(c1_bootstrap, X_full, params_full)\n",
    "                \n",
    "                # Calculate and store the likelihood ratio\n",
    "                likelihood_ratio = likelihood_with_delta - likelihood_no_delta\n",
    "                likelihood_ratios[i, draw * bootstrap_iterations + j] = likelihood_ratio\n",
    "    \n",
    "    return likelihood_ratios\n",
    "\n",
    "# Function to calculate log-likelihood\n",
    "def calculate_log_likelihood(c1_bootstrap, X, params):\n",
    "    model = OLS_loglike(c1_bootstrap, X)\n",
    "    log_like_val = model.loglikeobs(params).sum()\n",
    "    return log_like_val\n",
    "\n",
    "# Perform simulation and calculate likelihood distributions\n",
    "likelihood_distributions = calculate_likelihood_distribution(c1, data, indices, true_break_point, num_draws, bootstrap_iterations)\n",
    "print(likelihood_distributions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
