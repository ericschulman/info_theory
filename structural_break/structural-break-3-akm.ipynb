{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8f9caa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F,delta (246.10445897458297, 3.1504933708783485)\n",
      "results [-inf  inf] [-inf  inf] 3.1504933708783485 0.04650789424181546\n",
      "-----\n",
      "F,delta (204.99906575154617, 3.149003237445142)\n",
      "results [       -inf -0.33930986] [3.14900324        inf] 3.149003237445142 0.03840888925855603\n",
      "-----\n",
      "F,delta (187.95439463185383, 2.8207949527443104)\n",
      "results [       -inf -2.84149548] [2.82079495        inf] 2.8207949527443104 0.04269918138622003\n",
      "-----\n",
      "F,delta (179.92140768539005, 2.906312162709424)\n",
      "results [      -inf 0.68170332] [2.90631216        inf] 2.906312162709424 0.06459174624203326\n",
      "-----\n",
      "F,delta (246.00017775343053, 2.922840021253212)\n",
      "results [      -inf 0.13811265] [2.92284002        inf] 2.922840021253212 0.03711895339898981\n",
      "-----\n",
      "F,delta (212.31523758174367, 2.973536484066029)\n",
      "results [      -inf 0.39929735] [2.97353648        inf] 2.973536484066029 0.03924339019656052\n",
      "-----\n",
      "F,delta (199.05052597746771, 3.0410368386813804)\n",
      "results [      -inf 0.58124562] [3.04103684        inf] 3.0410368386813804 0.04276995730089749\n",
      "-----\n",
      "F,delta (242.28079698509674, 3.082008377819541)\n",
      "results [     -inf 0.0590094] [3.08200838        inf] 3.082008377819541 0.038122278884571564\n",
      "-----\n",
      "F,delta (164.988944789127, 2.9554489410327376)\n",
      "results [      -inf 0.81080178] [2.95544894        inf] 2.9554489410327376 0.043611359319806815\n",
      "-----\n",
      "F,delta (173.47845591821383, 3.183048731160581)\n",
      "results [       -inf -2.26752266] [3.18304873        inf] 3.183048731160581 0.06214499369087441\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def generate_data(n, break_point, beta, delta):\n",
    "    index = np.arange(n).reshape(-1, 1)  # Creating an index column\n",
    "    c2 = np.random.normal(size=n)  # Making c2 a column vector\n",
    "    c2_with_index = np.column_stack((index, c2))  # Including index as a column\n",
    "    e = np.random.normal(size=n)\n",
    "    c1 = beta * c2 + e\n",
    "    c1[break_point:] += delta * c2[break_point:]\n",
    "    return c1, c2_with_index\n",
    "\n",
    "\n",
    "def compute_f_stat_and_delta(c1, c2_with_index, theta):\n",
    "    index = c2_with_index[:, 0]\n",
    "    c2 = c2_with_index[:, 1]\n",
    "    X_unrestricted = sm.add_constant(np.column_stack((c2, (index >= theta) * c2)))\n",
    "    X_restricted = sm.add_constant(c2[:, np.newaxis])\n",
    "\n",
    "    # Solve for unrestricted coefficients\n",
    "    unrestricted_model = np.linalg.lstsq(X_unrestricted, c1, rcond=None)\n",
    "    unrestricted_coeffs = unrestricted_model[0]\n",
    "    ssr_unrestricted = ((c1 - X_unrestricted @ unrestricted_coeffs) ** 2).sum()\n",
    "\n",
    "    restricted_model = np.linalg.lstsq(X_restricted, c1, rcond=None)\n",
    "    restricted_coeffs = restricted_model[0]\n",
    "    ssr_restricted = ((c1 - X_restricted @ restricted_coeffs) ** 2).sum()\n",
    "\n",
    "    delta = unrestricted_coeffs[2]\n",
    "    k = 2  # number of unrestricted coefficients\n",
    "    f_stat = ((ssr_restricted - ssr_unrestricted) / (k-1)) / (ssr_unrestricted / (len(c2) - k))\n",
    "    return f_stat, delta\n",
    "\n",
    "\n",
    "def bootstrap_covariance(c1, c2_with_index, theta_tilde, theta_i, n_bootstraps=1000):\n",
    "    results = []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        c1_b, c2_b_with_index = resample(c1, c2_with_index)\n",
    "\n",
    "        f_stat_tilde, delta_tilde = compute_f_stat_and_delta(c1_b, c2_b_with_index, theta_tilde)\n",
    "        f_stat_i, delta_i = compute_f_stat_and_delta(c1_b, c2_b_with_index, theta_i)\n",
    "\n",
    "        results.append((f_stat_i, delta_i, f_stat_tilde, delta_tilde))\n",
    "\n",
    "    return np.cov(list(zip(*results)))\n",
    "\n",
    "\n",
    "def compute_matrices(cov_matrix, f_stat_tilde, delta_tilde,print_stuff=False):\n",
    "    ΣYX_true, ΣY_tilde = cov_matrix[1, 0], cov_matrix[3, 3]\n",
    "    ΣXY_tilde = cov_matrix[2, 3]\n",
    "    ΣYX = cov_matrix[0, 3]# really need the covariance between x and y_tilde\n",
    "    # y and x_tilde would be cov_matrix[1,2]\n",
    "    ΣX, ΣX_tilde = cov_matrix[0, 0], cov_matrix[2, 2]\n",
    "\n",
    "    # Projection calculations using the provided formulation\n",
    "    Z = f_stat_tilde - (ΣYX / ΣY_tilde) * delta_tilde\n",
    "    Z_tilde = f_stat_tilde - (ΣXY_tilde / ΣY_tilde) * delta_tilde\n",
    "    A = ΣY_tilde**(-2) * (ΣXY_tilde**2 - ΣYX**2)\n",
    "    B = 2 * ΣY_tilde**(-1) * (ΣXY_tilde * Z_tilde - ΣYX * Z)\n",
    "    C = Z_tilde**2 - Z**2\n",
    "\n",
    "    D = B ** 2 - 4 * A * C\n",
    "    H = -C / B if B != 0 else np.nan\n",
    "    G = (-B - np.sqrt(D)) / (2 * A) if D >= 0 and A!=0 else np.nan\n",
    "    K = (-B + np.sqrt(D)) / (2 * A) if D >= 0 and A!=0 else np.nan\n",
    "    if print_stuff:\n",
    "        print('------------------')\n",
    "        print(cov_matrix)\n",
    "        print(ΣYX,'//',cov_matrix[0, 3],  cov_matrix[3, 0],'//',cov_matrix[1,2],cov_matrix[1, 2],'//',ΣYX_true,cov_matrix[0, 1])\n",
    "        \n",
    "    return A, B, C, D, H, G, K\n",
    "\n",
    "\n",
    "\n",
    "def compute_confidence_intervals(theta_tilde, candidate_breaks, c1, c2,a_cutoff=1,print_stuff=False):\n",
    "    # Cache the intensive computations for reuse in other functions\n",
    "    cached_results = {}\n",
    "    f_stat_tilde, delta_tilde = compute_f_stat_and_delta(c1, c2, theta_tilde)\n",
    "    \n",
    "    # Perform all necessary computations and cache results\n",
    "    for theta in candidate_breaks:\n",
    "        cov_matrix = bootstrap_covariance(c1, c2, theta_tilde, theta)\n",
    "        if theta==theta_tilde:\n",
    "            bootstrap_covariance(c1, c2, theta_tilde, theta)\n",
    "        cached_results[theta] = (cov_matrix, f_stat_tilde, delta_tilde)\n",
    "    \n",
    "    sigma = cached_results[theta][0][3,3] #save self covariance... for the confidence intervals later...\n",
    "    \n",
    "    # Pre-calculate fixed intervals for each side\n",
    "    l1Z = calc_l1Z(candidate_breaks, cached_results,a_cutoff=a_cutoff)\n",
    "    u2Z = calc_u2Z(candidate_breaks, cached_results,a_cutoff=a_cutoff)\n",
    "    if print_stuff:\n",
    "        print('lz1 u2z',l1Z,u2Z)\n",
    "        print('----------')\n",
    "    \n",
    "    \n",
    "    left_intervals = {theta: [l1Z, np.inf] for theta in candidate_breaks}\n",
    "    right_intervals = {theta: [-np.inf, u2Z] for theta in candidate_breaks}\n",
    "    # Loop through candidate breaks to compute intervals\n",
    "    #print(left_intervals)\n",
    "    for theta in candidate_breaks:\n",
    "        cov_matrix, f_stat_tilde, delta_tilde = cached_results[theta]\n",
    "        A, B, C, D, H, G, K = compute_matrices(cov_matrix, f_stat_tilde, delta_tilde,print_stuff=print_stuff)\n",
    "            \n",
    "        left_intervals[theta][1] = min(u2Z,G) #l2Z \n",
    "        right_intervals[theta][0] = max(l1Z,K) #u1Z\n",
    "        \n",
    "        #only consider inervals where A>0 and D>0...\n",
    "        if A < a_cutoff or D < 0: #real condition im checking is A<0... but, even slightly bigger than 0 is a problem...\n",
    "            left_intervals[theta] = np.array([-np.inf,np.inf])\n",
    "            right_intervals[theta] = np.array([-np.inf,np.inf])\n",
    "            \n",
    "        if print_stuff:\n",
    "            print(theta,'//',A,B,C,D,\"//HGK\",H,G,K)\n",
    "            print(left_intervals[theta])\n",
    "            print('------------------')\n",
    "    #among the 40 by 2 array, find the interesection... e.g.,\n",
    "    left_interval_array = np.array([left_intervals[theta] for theta in candidate_breaks])\n",
    "    right_interval_array = np.array([right_intervals[theta] for theta in candidate_breaks])\n",
    "    #print(right_interval_array)\n",
    "    left_final = [left_interval_array[:,0].max(),left_interval_array[:,1].min()]\n",
    "    right_final = [right_interval_array[:,0].max(),right_interval_array[:,1].min()]\n",
    "\n",
    "    return np.array(left_final), np.array(right_final),delta_tilde,sigma\n",
    "\n",
    "\n",
    "def calc_l1Z(candidate_breaks, cached_results,a_cutoff=1):\n",
    "    max_G = -np.inf\n",
    "    max_H = -np.inf\n",
    "    \n",
    "    for theta in candidate_breaks:\n",
    "        cov_matrix, f_stat_tilde, delta_tilde = cached_results[theta]\n",
    "        A, B, C, D, H, G, K = compute_matrices(cov_matrix, f_stat_tilde, delta_tilde)\n",
    "        if A < -a_cutoff and D >= 0: #should really be A<0...\n",
    "            max_G = max(max_G, G)\n",
    "        if np.abs(A) == 0 and B > 0:  #technically should be a==0\n",
    "            max_H = max(max_H, H)\n",
    "\n",
    "    return max(max_G,max_H)\n",
    "\n",
    "\n",
    "def calc_u2Z(candidate_breaks, cached_results,a_cutoff=1):\n",
    "    min_K = np.inf\n",
    "    min_H = np.inf\n",
    "    \n",
    "    for theta in candidate_breaks:\n",
    "        cov_matrix, f_stat_tilde, delta_tilde = cached_results[theta]\n",
    "        A, B, C, D, H, G, K = compute_matrices(cov_matrix, f_stat_tilde, delta_tilde)\n",
    "        if A < -a_cutoff and D >= 0: #should really be A<0...\n",
    "            min_K = min(min_K, K)\n",
    "        if np.abs(A) == 0  and B<0: #technically should be a==0\n",
    "            min_H = min(min_H, H)\n",
    "    return min(min_K,min_H)\n",
    "\n",
    "\n",
    "n = 100\n",
    "true_break_point = 50\n",
    "beta = 2\n",
    "delta = 3\n",
    "A_CUTOFF = 5000 # this is like a mangitude of 1/100 of A...\n",
    "    \n",
    "for i in range(10):\n",
    "    # Generate data with an index column in c2\n",
    "    c1, c2_with_index = generate_data(n, true_break_point, beta, delta)\n",
    "\n",
    "    # Define the range of candidate break points\n",
    "    candidate_breaks = np.arange(35, 65)\n",
    "\n",
    "    # Find the theta where the maximum F-statistic occurs\n",
    "    theta_hat, max_f_stat = max(\n",
    "        ((theta, compute_f_stat_and_delta(c1, c2_with_index, theta)[0]) for theta in candidate_breaks),\n",
    "        key=lambda x: x[1]\n",
    "    )\n",
    "\n",
    "    print('F,delta',compute_f_stat_and_delta(c1, c2_with_index, theta_hat))\n",
    "    interval_left, interval_right,mean, variance = compute_confidence_intervals(theta_hat, candidate_breaks, c1,\n",
    "                                                                                 c2_with_index ,a_cutoff=A_CUTOFF)\n",
    "\n",
    "\n",
    "\n",
    "    print('results',interval_left, interval_right,mean, variance )\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc8feb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.198680839639377 3.671646146397083\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def truncated_normal_quantile(quantile, interval_left, interval_right, mean, variance):\n",
    "    # Unpack intervals\n",
    "    l1, u1 = interval_left\n",
    "    l2, u2 = interval_right\n",
    "    \n",
    "    # Standardize the intervals with the mean and variance\n",
    "    l1_std, u1_std = (l1 - mean) / np.sqrt(variance), (u1 - mean) / np.sqrt(variance)\n",
    "    l2_std, u2_std = (l2 - mean) / np.sqrt(variance), (u2 - mean) / np.sqrt(variance)\n",
    "    \n",
    "    # Calculate the probabilities over the two intervals\n",
    "    P1 = norm.cdf(u1_std) - norm.cdf(l1_std)\n",
    "    P2 = norm.cdf(u2_std) - norm.cdf(l2_std)\n",
    "    \n",
    "    # Total probability considering the truncated intervals\n",
    "    P_total = P1 + P2\n",
    "    \n",
    "    # Target cumulative probability adjusted for truncation\n",
    "    adjusted_quantile = quantile * P_total\n",
    "    \n",
    "    # Determine in which interval the quantile lies\n",
    "    if adjusted_quantile <= P1:\n",
    "        # Quantile lies in the first interval\n",
    "        quantile_value_std = norm.ppf(norm.cdf(l1_std) + adjusted_quantile)\n",
    "    else:\n",
    "        # Quantile lies in the second interval\n",
    "        adjusted_quantile -= P1\n",
    "        quantile_value_std = norm.ppf(norm.cdf(l2_std) + adjusted_quantile)\n",
    "\n",
    "    # Convert back to the original scale\n",
    "    quantile_value = quantile_value_std * np.sqrt(variance) + mean\n",
    "    \n",
    "    return quantile_value\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "quantile_upper = truncated_normal_quantile(.95, interval_left, interval_right, mean, variance)\n",
    "quantile_lower = truncated_normal_quantile(.05, interval_left, interval_right, mean, variance)\n",
    "print(quantile_lower,quantile_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178342d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
